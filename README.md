# TinyML-projects-using-Edge-Impulse
I. Continuous Motion Recognition using Edge Impulse

The Continuous Motion Recognition work focuses on leveraging Tiny Machine Learning (TinyML) to enable real-time motion classification on embedded hardware. It utilizes the Texas Instruments CC1352P LaunchPad along with Booster Sensors to collect motion data, process it, and deploy a trained machine learning model for on-device inference. The workflow begins with data acquisition, where motion signals are captured using TI sensors (snake, wave, up-down, idle), followed by feature extraction through spectral analysis. The processed data is then used to train a neural network within Edge Impulse, optimizing it for efficient classification while ensuring it remains lightweight for deployment on a resource-constrained embedded system. After training, the model is flashed onto the TI CC1352P LaunchPad, allowing real-time motion classification directly on the device without requiring external computation. The system was thoroughly tested and validated, demonstrating the effectiveness of TinyML for real-time motion recognition, making it an ideal solution for applications requiring low-power, edge-based intelligence.

II. Audio Classification using Edge Impulse

The Audio Classification is a TinyML-based embedded systems implementation focused on real-time sound recognition. It uses the Texas Instruments CC1352P LaunchPad along with Booster Sensors to collect and classify audio signals. The system is designed to distinguish between different audio patterns, such as background noise and running faucet sounds, using machine learning algorithms optimized for edge computing.
The workflow begins with data acquisition, where audio signals are sampled and processed using the MFE block and spectral analysis. These extracted features are then used to train a neural network in Edge Impulse, ensuring efficient classification while maintaining a lightweight footprint for deployment on the TI CC1352P. The trained model is then deployed back to the embedded hardware, enabling real-time on-device classification without reliance on cloud computing. The system was rigorously tested, demonstrating the potential of TinyML for real-time audio recognition, making it ideal for low-power, edge-based applications.

III. Image Classification using Edge Impulse

This demonstrates the implementation of TinyML for real-time image classification using the ESP-EYE (ESP32) development board, leveraging Edge Impulse for dataset collection, model training, and deployment. The system captures images using the ESP-EYE's built-in camera and classifies objects such as lamps, flowers, and mountains. The process begins with data acquisition, where multiple images of each object category are collected and uploaded to Edge Impulse. Feature extraction is performed using a preprocessing block that resizes images, converts them to grayscale (if necessary), and extracts pixel-based features. The extracted features are then used for training a neural network using transfer learning, which allows for efficient training even with a small dataset. The trained model is validated using a separate test dataset to ensure it generalizes well and is not overfitting. Once validated, the optimized model is deployed back to the ESP-EYE as a compact C++ library, allowing it to run low-latency, offline inference directly on the embedded device. This approach ensures minimal power consumption and eliminates the need for constant cloud connectivity. The project highlights the potential of embedded AI, enabling small, low-power devices to perform real-time image classification for IoT and smart automation applications.
